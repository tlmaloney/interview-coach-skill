# Detailed Scoring Rubrics

Use these expanded rubrics when doing deep analysis. The compact version in SKILL.md is for quick scoring.

## Substance (Evidence Quality)

| Score | Description | Example |
|-------|-------------|---------|
| 1 | Generic platitude, no evidence | "I'm a great collaborator" |
| 2 | Vague claim with weak support | "I improved the process and people liked it" |
| 3 | Specific claim, missing quantification | "I redesigned the onboarding flow and reduced drop-off" |
| 4 | Quantified with context, missing alternatives considered | "I redesigned onboarding, reducing drop-off from 40% to 25%" |
| 5 | Quantified + alternatives weighed + decision rationale + outcome | "I redesigned onboarding after testing 3 approaches. We chose progressive disclosure over a wizard because our data showed users abandoned at step 3. Drop-off fell from 40% to 25%, validated over 10K users." |

**Coaching notes:**
- Push for numbers even when "hard to measure" — approximations with caveats are better than none
- Ask: "What would a skeptic say is missing from this evidence?"
- Flag when impact is claimed without explaining the candidate's specific contribution

**Root causes when stuck at 1-2:**
- Candidate hasn't done the reflection work — they know what happened but haven't extracted what mattered
- Conflict avoidance: stripping stories of tension, stakes, and difficulty makes evidence disappear
- Impostor syndrome: downplaying real impact because they feel they don't deserve the credit

**Root causes when stuck at 3:**
- "Good enough" syndrome — candidate has specifics but stops before quantifying because it feels like bragging
- Hasn't thought about alternatives considered — they know what they did, not why they chose it over other options
- Missing the "so what" — evidence exists but isn't connected to business impact

## Structure (Narrative Clarity)

| Score | Description | Example |
|-------|-------------|---------|
| 1 | Stream of consciousness, no clear point | Jumps between topics, listener lost |
| 2 | Central idea unclear until the end | Buries the lead, meanders to point |
| 3 | Clear structure but missing transitions | Good STAR but choppy between sections |
| 4 | Well-structured with smooth flow, minor tangents | Clean arc with one or two detours |
| 5 | Crisp structure: setup → conflict → resolution → impact | Every sentence advances the story, lands with clear takeaway |

**Coaching notes:**
- Best answers front-load the headline: "The key learning was X. Here's how we got there..."
- Tangents often signal the candidate is unsure what matters — help them identify the core
- Practice the "30-second version" to force clarity on what's essential

**Root causes when stuck at 1-2:**
- Narrative hoarding: trying to cram everything into one answer because they're afraid of leaving out something important
- No mental model for story structure — they've never been taught to think in setup → conflict → resolution → impact
- Anxiety-driven stream of consciousness: stress breaks whatever structure they had in their head

**Root causes when stuck at 3:**
- Knows the STAR framework but applies it mechanically — transitions feel forced, not natural
- Hasn't practiced at multiple time constraints — can deliver a 3-minute version but can't compress or expand

## Relevance (Question Fit)

| Score | Description | Example |
|-------|-------------|---------|
| 1 | Doesn't address the question asked | Asked about conflict, answers about a successful launch |
| 2 | Tangentially related, misses core of question | Asked about failure, talks about a challenge they overcame easily |
| 3 | Addresses question but includes irrelevant details | Right story but 40% of answer is background noise |
| 4 | Directly addresses question with minor drift | Solid answer with one unnecessary tangent |
| 5 | Laser-focused, every sentence serves the answer | Could not remove a single sentence without losing value |

**Coaching notes:**
- Restate the question before answering to ensure alignment
- Common failure: using a "favorite" story that doesn't quite fit
- Ask: "If the interviewer only remembers one thing, what should it be?"

**Root causes when stuck at 1-2:**
- Inability to identify the core of a question: the candidate hears a topic ("conflict") and defaults to their conflict story regardless of what specific aspect the question targets
- Poor question decoding: doesn't distinguish between "tell me about a conflict" vs. "tell me about a conflict where you were wrong" vs. "how do you handle conflict with senior stakeholders"
- Story-first thinking: starts from "which story do I want to tell?" instead of "what is this question actually asking?"

**Root causes when stuck at 3:**
- Right story, wrong framing: the experience is relevant but 30-40% of the answer is context that doesn't serve the question
- Doesn't check mid-answer whether they're still on track — no internal "am I answering what they asked?" monitor

## Credibility (Believability)

| Score | Description | Example |
|-------|-------------|---------|
| 1 | Claims with no support or obvious exaggeration | "I single-handedly transformed the company culture" |
| 2 | Support is vague or generic | "I increased efficiency" (how? by how much?) |
| 3 | Specific details but missing numbers or outcomes | "I built a dashboard the team used daily" (impact?) |
| 4 | Quantified with context, could use stronger proof points | "Dashboard reduced reporting time by 50%" (validated how?) |
| 5 | Numbers + artifacts + validation from others + realistic constraints | "Dashboard cut reporting from 4 hours to 2 (verified by team survey). CEO mentioned it in all-hands. Took 3 weeks to build with one engineer." |

**Coaching notes:**
- Credibility increases when candidate acknowledges constraints and trade-offs
- Third-party validation (quotes, awards, metrics from others) strengthens claims
- Watch for "we" vs "I" confusion — interviewers want to know the candidate's specific role
- Realistic timelines and resource constraints make stories more believable

**Root causes when stuck at 1-2:**
- Over-claiming / status anxiety: candidate feels a perceived gap in their background and compensates by inflating contributions. This actually *reduces* credibility — interviewers sense it immediately
- Reflexive "we" framing: candidate obscures their individual contribution, often because they're uncertain about how much credit they can claim
- Fabrication: making up or heavily embellishing details (this is a red flag, not a coaching gap — address directly)

**Root causes when stuck at 3:**
- Has the details but doesn't package them as proof — specific facts exist but aren't connected to a credibility chain (claim → action → evidence → validation)
- Missing third-party signals: never quotes what others said about the work, never mentions recognition or adoption metrics

## Differentiation (Uniqueness)

| Score | Description | Example |
|-------|-------------|---------|
| 1 | Generic answer any prepared candidate could give | "I used data to make better decisions" — could be anyone |
| 2 | Some specificity but relies on common frameworks | "I applied the RICE framework to prioritize" — correct but undifferentiated |
| 3 | Real details present but no earned insight or defensible POV | "I built a dashboard that saved 10 hours/week" — specific but not distinctive |
| 4 | Includes earned secrets or a spiky POV; sounds like a specific person | "I learned that the fastest way to kill a feature is to let it succeed at small scale — it becomes politically unkillable before you have real data" |
| 5 | Unmistakably this candidate — earned secrets + defensible stance + unique framing | "After launching 12 features in 2 years, I developed a 'kill threshold' system. If a feature doesn't hit 40% adoption in 6 weeks, I kill it regardless of stakeholder enthusiasm. Three of those kills freed resources for our actual breakout product. Most PMs can't do this because they optimize for shipping, not for pruning." |

**Coaching notes:**
- Differentiation is what separates a Hire from a Strong Hire in competitive processes
- The biggest enemy of differentiation is AI-polished prep — answers that sound "correct" but could be anyone's
- Push candidates to find their earned secrets: "What do you know from this experience that most people in your role wouldn't know?"
- Spiky POVs must be defensible, authentic, and backed by experience — not manufactured controversy

**Root causes when stuck at 1-2:**
- Over-reliance on frameworks and best practices — answering like a textbook instead of a practitioner
- Fear of being wrong: candidates choose "safe" answers over distinctive ones because distinctive answers are debatable
- Haven't done the reflection work to extract what's unique about their experience

**Root causes when stuck at 3:**
- Has real experience but presents it as straightforward execution, not as insight
- Doesn't realize what makes their perspective unusual — it feels "obvious" to them because they lived it
- Missing the spiky POV: has the facts but not the opinionated interpretation of what they mean

---

## Root Cause Taxonomy (Cross-Dimensional)

Most interview failures trace back to a small number of root causes that manifest across multiple dimensions. When diagnosing, look for these patterns:

| Root Cause | How It Manifests | Affected Dimensions | Targeted Fix |
|---|---|---|---|
| **Inability to identify question core** | Answers miss the point, wrong story selected | Relevance, Structure | Question-decoding drills: restate what the question is really asking before answering |
| **Reflexive "we" framing** | Individual contribution unclear, credibility suffers | Credibility, Substance | "I/we" audit: go through every answer and replace "we" with specific individual actions |
| **Conflict avoidance** | Stories lack tension, stakes, and difficulty | Substance, Differentiation | Tension-mining: for every story, identify the hardest moment and make it the centerpiece |
| **Status anxiety / over-claiming** | Inflated claims that interviewers don't believe | Credibility, Differentiation | Constraint practice: add realistic limitations, timelines, and trade-offs to every claim |
| **Narrative hoarding** | Answers run long, structure collapses under weight of detail | Structure, Relevance | Constraint ladder drill: force 30s, 60s, 90s versions to find what's essential |
| **Fear of being wrong** | Generic, safe answers that sound like everyone else | Differentiation, Substance | Spiky POV practice: take a stance, defend it, practice being comfortable with disagreement |
| **Anxiety/performance stress** | Structure breaks, retrieval fails, spiral after mistakes | Structure, all dimensions | Psychological readiness module: warmup routines, mid-interview recovery scripts |
| **Cultural communication style** | Indirect framing, modesty in self-description, different narrative structures | Credibility, Structure, Substance | Adaptation coaching: help map natural style to interview expectations without erasing voice. "This is a style difference, not a skill deficit." |
| **Linguistic formality** | Overly formal tone, avoidance of colloquial language, occasional idiom misuse | Differentiation, Credibility | Gentle calibration on register. Slight formality is fine — better than forced casualness. Focus on clarity, not idiom. |

When scoring reveals a pattern, name the root cause explicitly: "This looks like [pattern X] — here's what typically drives it and here's the targeted drill." For cultural/linguistic patterns specifically, always frame as adaptation, not correction.

---

## Seniority Calibration

Scoring is not absolute — calibrate expectations to career stage. When scoring, always state which calibration band you're using.

- **Early career (0-3 years)**: A "4 on Substance" means specific examples with at least one metric. Differentiation can come from learning velocity and intellectual curiosity. Expect less systems-level thinking; look for self-awareness about what they don't yet know.
- **Mid-career (4-8 years)**: A "4 on Substance" means quantified impact with alternatives considered. Differentiation requires genuine earned secrets from hands-on work. Should demonstrate ownership of outcomes, not just tasks.
- **Senior/Lead (8-15 years)**: A "4 on Substance" means systems-level thinking — second-order effects, organizational impact. Differentiation requires insights that reshape how the interviewer thinks about the problem. Should show judgment across ambiguous tradeoffs.
- **Executive (15+ years)**: A "4 on Substance" means business-level impact with P&L awareness. Differentiation requires a coherent leadership philosophy backed by pattern recognition across multiple contexts. Should demonstrate how they build and scale through others.

---

## Aggregate Scoring

After scoring individual answers:

### Interview-Level Assessment

| Rating | Criteria |
|--------|----------|
| **Strong Hire** | Multiple 4-5 scores, no major gaps, demonstrated unique value |
| **Hire** | Mostly 3-4 scores, minor gaps that could be coached |
| **Mixed** | Inconsistent scores, some strengths but concerning gaps |
| **No Hire** | Multiple low scores, significant evidence gaps, or red flags |

### Trend Analysis (across multiple interviews)

Track average scores per dimension over time:
- Improving: +0.5 or more from baseline
- Stagnant: Within ±0.3 of baseline
- Declining: -0.5 or more from baseline

Stagnant scores after 3+ interviews signal need to change approach, not just practice more. When presenting this to the person, explore what's blocking progress: "These scores have been steady for a few rounds. What do you think is getting in the way?"
